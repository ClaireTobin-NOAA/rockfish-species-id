---
title: "assign sample mixture with rubias"
output: html_notebook
---

We want to create a more liberal missing data threshold that is appropriate for species that are phylogentically distant from kelp rockfish.

Much of this is redundant from `01-aggregate-genos-and-gsi-to-species` but without the missing data threshold of 15 loci.

To start off with, let's load data and libs:
```{r load-stuff}
library(tidyverse)
library(CKMRsim)
library(stringr)
library(readxl)

#meta <- readRDS("../data/processed/meta-data-tibble.rds") # not worrying about meta data right now...
genos <- readRDS("../data/processed/called_genos_na_explicit.rds") #%>%
  #filter(NMFS_DNA_ID %in% meta$NMFS_DNA_ID)  # drop those we don't have meta data for
samples <- readRDS("../data/processed/sample-sheet-tibble.rds") #%>%
  #filter(NMFS_DNA_ID %in% meta$NMFS_DNA_ID)

# meta data for OSU samples
batch_4792 <- read_csv("../extdata/batch4792.csv")
batch_4969 <- read_csv("../extdata/batch4969.csv")
batch_4969_ext <- read_csv("../extdata/batch4969_addition.csv")


# somehow the structure for the sample IDs is different in the two files...
# change that.
batch_4792$SAMPLE_ID <- as.character(batch_4792$SAMPLE_ID)
batch_4969_ext$SAMPLE_ID <- as.character(batch_4969_ext$SAMPLE_ID)

# bind those things together
meta <- bind_rows(batch_4969, batch_4792, batch_4969_ext)
```
## Some initial filters

### Take highest read-depth call for multiply-genotyped DNA_IDs

I'm not sure if there are any of these, but best to leave it in here...
particularly for the re-genotyped fish from Brittany's OSU samples.

Now, here is a harder operation: if an individual is multiply-genotyped, take the
genotype with the highest total read depth.  
```{r take-just-one}
# slow-ish function to get the total read depth column
tdepth <- function(a, d) {
  if(any(is.na(a))) {
    return(NA)
  }
  if(a[1]==a[2]) {
    return(d[1])
  } else {
    return(d[1] + d[2])
  }
  
}
# this takes the highest read-depth instance of each duplicately-genotyped individual.
geno_one_each <- genos %>%
  group_by(NMFS_DNA_ID, locus, gtseq_run, id) %>%
  mutate(total_depth = tdepth(allele, depth)) %>%
  ungroup() %>%
  arrange(NMFS_DNA_ID, locus, total_depth, gtseq_run, id, depth) %>%
  group_by(NMFS_DNA_ID, locus) %>%
  mutate(rank = 1:n()) %>%
  ungroup() %>%
  filter(rank <= 2)
```

### Remove the 6 loci which Hayley has been removing

```{r remove-loci}
# read in a list of the 6 loci
to_remove <- read_csv("../data/loci_to_remove.csv")

# only keep the loci that are not those 6
keepers <- geno_one_each %>%
  anti_join(., to_remove, by = "locus")

# that should leave 90 loci  
```
What does the distribution of missing data look like?
```{r distribution-missing-data}
keepers %>%
  group_by(NMFS_DNA_ID) %>%
  select(NMFS_DNA_ID, allele) %>%
  tally(is.na(allele)) %>%
  mutate(missing_loci = n/2) %>%
  arrange(desc(missing_loci))

```
There are 90 total loci, so we don't want to include samples with fewer than 25 loci with data.

### Toss out indivs with data at fewer than 25 loci
Now, toss out any individual with fewer than 25 non-missing loci
```{r toss-missers}
no_hi_missers <- keepers %>% 
  group_by(NMFS_DNA_ID) %>%
  filter(sum(!is.na(allele)) >= (25*2))
```
So, we started with `r length(unique(geno_one_each$NMFS_DNA_ID))` 
and after filtering out indivs with fewer than 75 genotyped loci, we were left with 
`r length(unique(no_hi_missers$NMFS_DNA_ID))` individuals.  Those are the ones that
we will run through rubias to identify to species.

## Read in baseline genotypes and remove loci and individuals with too much missing data

```{r read-spp-genos}
# read in genotypes identified to species using rubias
spp <- read_csv("../data/reported_haplotype_SebSppID_11102017.csv")

select_spp <- spp %>%
  select(group, locus, indiv.ID, haplotype.1, haplotype.2)

spp.id <- select_spp %>%
  gather("gene_copy", "allele", 4:5) %>%
  mutate(gene_copy = ifelse(gene_copy == "haplotype.1", 1, 2))

# only keep the loci that are not the 6 removed from the previous dataset
spp.id_loc <- spp.id %>%
  anti_join(., to_remove, by = "locus")
# that should leave 90 loci 

# remove samples with missing data at more than 15 loci (per Hayley's workflow)
#spp.id_no_missers <- spp.id_loc %>%
#  group_by(indiv.ID) %>%
#  filter(sum(!is.na(allele)) >= (75*2))

# add reference column to prepare data for rubias
spp.id_loc1 <- spp.id_loc %>%
  mutate(sample_type = "reference")

x <- spp.id_loc1 %>%
  mutate(repunit = group)

# reorder the columns and get it in the right format
spp.id1 <- x[,c(6,7,1,3,2,4:5)]
spp.id2 <- spp.id1 %>%
  rename(collection = group) %>%
  rename(indiv = indiv.ID)

# get the data frames into the same format
no_hi_missers2 <- no_hi_missers %>%
  dplyr::select(NMFS_DNA_ID, locus, gene_copy, allele) %>%
  rename(indiv = NMFS_DNA_ID) %>%
  mutate(sample_type = "mixture") %>%
  mutate(repunit = NA) %>%
  mutate(collection = "osu_samples")

# reorder
no_hi_missers2[, c(5:7,1:4)]

# combine the data into a single df
alleles <- bind_rows(spp.id2, no_hi_missers2)

alleles
```
We are going to do this by turning alleles into integers and spreading it and then getting it into the right format to run rubias.
```{r spread-genos}
# first make integers of the alleles
alle_idxs <- alleles %>% 
  #dplyr::select(NMFS_DNA_ID, locus, gene_copy, allele) %>%
  group_by(locus) %>%
  mutate(alleidx = as.integer(factor(allele, levels = unique(allele)))) %>%
  ungroup() %>%
  arrange(indiv, locus, alleidx) # rubias can handle NA's, so no need to change them to 0's
  
# select just the columns to retain and spread the alleles
alle_idx2 <- alle_idxs[,-7]
  
two_col <- alle_idx2 %>%
  unite(loc, locus, gene_copy, sep = ".") %>%
  spread(loc, alleidx)

two_col

# write this file to a thing that can be read-into other softwares
#two_col %>%
# write_csv("csv_outputs/genos_two_col.csv")
```
I need to use `infer_mixture` in rubias, which requires two separate data frames, one with the reference genotypes and the other with the mixture. 

I'll split the data frame that I created, but it needed to be bunged together for the conversion of alleles to integers.

```{r split-frames}
# split up the reference and mixture data frames
sp_mix <- two_col %>%
  filter(sample_type == "mixture")

sp_ref <- two_col %>%
  filter(sample_type == "reference")
```


```{r run-rubias}
# Now that the data are in the corret format, load Rubias
library(rubias)

# perform self-assignment of reference samples
ref_self <- self_assign(sp_ref, gen_start_col = 5)

# and take a quick look at those assignments
ref_self %>%
  filter(inferred_repunit == repunit) %>%
  filter(scaled_likelihood > 0.95)

```

Look at any samples that were assigned at lower than .95 in the baseline 
(this is one way I will deal with the missing data bias across phylogenetic distance)
```{r remove-losers}
ref_self %>%
  filter(inferred_repunit == repunit) %>%
  filter(scaled_likelihood < 0.95) %>%
  arrange(desc(n_miss_loci))


```
A bunch of black-and-yellow and gopher samples.
I think I'll keep everybody in for this analysis.

```{r run-mixture}
# perform mixture-assignment on baseline colony samples
mix_assign <- infer_mixture(reference = sp_ref, mixture = sp_mix, gen_start_col = 5, method = "MCMC", reps = 2000, burn_in = 100)

# That was fast, let's take a look
head(mix_assign)

# the individual data is in 
mix_assign$indiv_posteriors %>%
  arrange(desc(log_likelihood))

# are there any rockfish that don't seem like the correct species is in the reference?
osu_assignments <- mix_assign$indiv_posteriors %>%
  filter(PofZ == 1)

osu_assign2 <- osu_assignments[,-10]

#write_csv(osu_assign2, "csv_outputs/osu_assignments.csv")

osu_assign2
```
The posterior means of group membership in each collection is in the PofZ column - there are 1,220 individuals with a PofZ = 1.

```{r lesser-assignments}
# I think there are individual assignments for each sample to each reference.
# I want to take only the top assignment for each sample.
kept_assignments <- mix_assign$indiv_posteriors %>%
  group_by(indiv) %>%
  filter(PofZ > 0.5) %>%
  arrange(desc(PofZ))

kept_assignments
```

Using a PofZ of 0.5, we keep everyone in the assignment data frame.

The `meta` file should contain all the samples for Brittany's project.

```{r meta-assign}
brit_all_assign <- meta %>%
  left_join(., kept_assignments, by = c("NMFS_DNA_ID" = "indiv"))

brit_all_assign %>%
  select(1:5,7:9,17,25:30) %>%
  write_csv("csv_outputs/osu_estuary_assignments_05pofz.csv")

# and a list of the samples that were not assigned (for one reason or another)
brit_missing <- brit_all_assign %>%
  anti_join(., kept_assignments, by = c("NMFS_DNA_ID" = "indiv")) %>%
  #group_by(BOX_ID) %>%
  #tally() 
  select(1:30) %>%
  write_csv("csv_outputs/osu_unassigned_samples_05pofz.csv")
  
```
Only three samples are missing without the missing data threshold of 15 loci and using a PofZ assignment threshold of > 0.5.


