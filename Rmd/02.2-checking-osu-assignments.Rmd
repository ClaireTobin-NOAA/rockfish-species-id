---
title: "checking copper assignments for Brittany (OSU)"
output: html_notebook
---

After the first set of species ID for Brittany's OSU estuary rockfish project, she had a couple of copper assignments that didn't make much sense biologically - i.e. the juveniles were VERY small in September, when typically copper rockfish extrude their larvae in early springtime.

I figured out that there were three copper samples in the baseline that assigned to gopher rockfish with high confidence (>0.95) and want to exclude those from a re-analysis just to see if that changes anything. 


To start off with, let's load data and libs:
```{r load-stuff}
library(tidyverse)
library(CKMRsim)
library(stringr)
library(readxl)

#meta <- readRDS("../data/processed/meta-data-tibble.rds") # not worrying about meta data right now...
genos <- readRDS("../data/processed/called_genos_na_explicit.rds") #%>%
  #filter(NMFS_DNA_ID %in% meta$NMFS_DNA_ID)  # drop those we don't have meta data for
samples <- readRDS("../data/processed/sample-sheet-tibble.rds") #%>%
  #filter(NMFS_DNA_ID %in% meta$NMFS_DNA_ID)

# meta data for OSU samples
batch_4792 <- read_csv("../extdata/batch4792.csv")
batch_4969 <- read_csv("../extdata/batch4969.csv")
batch_4969_ext <- read_csv("../extdata/batch4969_addition.csv")


# somehow the structure for the sample IDs is different in the two files...
# change that.
batch_4792$SAMPLE_ID <- as.character(batch_4792$SAMPLE_ID)
batch_4969_ext$SAMPLE_ID <- as.character(batch_4969_ext$SAMPLE_ID)

# bind those things together
meta <- bind_rows(batch_4969, batch_4792, batch_4969_ext)
```

## Some initial filters

### Take highest read-depth call for multiply-genotyped DNA_IDs

I'm not sure if there are any of these, but best to leave it in here...
particularly for the re-genotyped fish from Brittany's OSU samples.

Now, here is a harder operation: if an individual is multiply-genotyped, take the
genotype with the highest total read depth.  
```{r take-just-one}
# slow-ish function to get the total read depth column
tdepth <- function(a, d) {
  if(any(is.na(a))) {
    return(NA)
  }
  if(a[1]==a[2]) {
    return(d[1])
  } else {
    return(d[1] + d[2])
  }
  
}
# this takes the highest read-depth instance of each duplicately-genotyped individual.
geno_one_each <- genos %>%
  group_by(NMFS_DNA_ID, locus, gtseq_run, id) %>%
  mutate(total_depth = tdepth(allele, depth)) %>%
  ungroup() %>%
  arrange(NMFS_DNA_ID, locus, total_depth, gtseq_run, id, depth) %>%
  group_by(NMFS_DNA_ID, locus) %>%
  mutate(rank = 1:n()) %>%
  ungroup() %>%
  filter(rank <= 2)
```

### Remove the 6 loci which Hayley has been removing

```{r remove-loci}
# read in a list of the 6 loci
to_remove <- read_csv("../data/loci_to_remove.csv")

# only keep the loci that are not those 6
keepers <- geno_one_each %>%
  anti_join(., to_remove, by = "locus")

# that should leave 90 loci  
```
What does the distribution of missing data look like?
```{r distribution-missing-data}
keepers %>%
  group_by(NMFS_DNA_ID) %>%
  select(NMFS_DNA_ID, allele) %>%
  tally(is.na(allele)) %>%
  mutate(missing_loci = n/2) %>%
  arrange(desc(missing_loci)) %>%
  filter(missing_loci > 25)

```
There are 90 total loci, so we don't want to include samples with fewer than 25 loci with data.

### Toss out indivs with data at fewer than 25 loci
Now, toss out any individual with fewer than 25 non-missing loci
```{r toss-missers}
no_hi_missers <- keepers %>% 
  group_by(NMFS_DNA_ID) %>%
  filter(sum(!is.na(allele)) >= (25*2))
```
So, we started with `r length(unique(geno_one_each$NMFS_DNA_ID))` 
and after filtering out indivs with fewer than 75 genotyped loci, we were left with 
`r length(unique(no_hi_missers$NMFS_DNA_ID))` individuals.  Those are the ones that
we will run through rubias to identify to species.

## Read in baseline genotypes and remove loci and individuals with too much missing data

```{r read-spp-genos}
# read in genotypes identified to species using rubias
spp <- read_csv("../data/reported_haplotype_SebSppID_11102017.csv")

select_spp <- spp %>%
  select(group, locus, indiv.ID, haplotype.1, haplotype.2)

spp.id <- select_spp %>%
  gather("gene_copy", "allele", 4:5) %>%
  mutate(gene_copy = ifelse(gene_copy == "haplotype.1", 1, 2))

# only keep the loci that are not the 6 removed from the previous dataset
spp.id_loc <- spp.id %>%
  anti_join(., to_remove, by = "locus")
# that should leave 90 loci 

# remove samples with missing data at more than 15 loci (per Hayley's workflow)
#spp.id_no_missers <- spp.id_loc %>%
#  group_by(indiv.ID) %>%
#  filter(sum(!is.na(allele)) >= (75*2))

# add reference column to prepare data for rubias
spp.id_loc1 <- spp.id_loc %>%
  mutate(sample_type = "reference")

x <- spp.id_loc1 %>%
  mutate(repunit = group)

# reorder the columns and get it in the right format
spp.id1 <- x[,c(6,7,1,3,2,4:5)]
spp.id2 <- spp.id1 %>%
  rename(collection = group) %>%
  rename(indiv = indiv.ID)

# get the data frames into the same format
no_hi_missers2 <- no_hi_missers %>%
  dplyr::select(NMFS_DNA_ID, locus, gene_copy, allele) %>%
  rename(indiv = NMFS_DNA_ID) %>%
  mutate(sample_type = "mixture") %>%
  mutate(repunit = NA) %>%
  mutate(collection = "osu_samples")

# reorder
no_hi_missers2[, c(5:7,1:4)]

# combine the data into a single df
alleles <- bind_rows(spp.id2, no_hi_missers2)

alleles
```
We are going to do this by turning alleles into integers and spreading it and then getting it into the right format to run rubias.
```{r spread-genos}
# first make integers of the alleles
alle_idxs <- alleles %>% 
  #dplyr::select(NMFS_DNA_ID, locus, gene_copy, allele) %>%
  group_by(locus) %>%
  mutate(alleidx = as.integer(factor(allele, levels = unique(allele)))) %>%
  ungroup() %>%
  arrange(indiv, locus, alleidx) # rubias can handle NA's, so no need to change them to 0's
  
# select just the columns to retain and spread the alleles
alle_idx2 <- alle_idxs[,-7]
  
two_col <- alle_idx2 %>%
  unite(loc, locus, gene_copy, sep = ".") %>%
  spread(loc, alleidx)

two_col

# write this file to a thing that can be read-into other softwares
#two_col %>%
# write_csv("csv_outputs/genos_two_col.csv")
```
I need to use `infer_mixture` in rubias, which requires two separate data frames, one with the reference genotypes and the other with the mixture. 

I'll split the data frame that I created, but it needed to be bunged together for the conversion of alleles to integers.

```{r split-frames}
# split up the reference and mixture data frames
sp_mix <- two_col %>%
  filter(sample_type == "mixture")

sp_ref <- two_col %>%
  filter(sample_type == "reference")
```

## Self-assignment

```{r run-rubias}
# Now that the data are in the corret format, load Rubias
library(rubias)

# perform self-assignment of reference samples
ref_self <- self_assign(sp_ref, gen_start_col = 5)

# and take a quick look at those assignments
ref_self %>%
  filter(inferred_repunit == repunit) %>%
  filter(scaled_likelihood > 0.95)

```

Look at any copper samples that were assigned at lower than .95 in the baseline 
(this is one way I will deal with the missing data bias across phylogenetic distance)
```{r remove-losers}
false_coppers <- ref_self %>%
  filter(inferred_repunit != repunit) %>%
  filter(scaled_likelihood > 0.75) %>%
  #arrange(desc(n_miss_loci))
  filter(collection == "Scaurinus") %>%
  select(indiv)

```

Exclude these three copper samples from the baseline and then re-run the self-assignment analysis:

```{r exclude-rerun}
# keep all of the samples except the false coppers
revised_ref <- sp_ref %>%
  anti_join(., false_coppers)

# perform self-assignment of reference samples
sa_revised <- self_assign(revised_ref, gen_start_col = 5)

# and take a quick look at those assignments
sa_revised %>%
  filter(inferred_repunit == repunit) %>%
  filter(scaled_likelihood > 0.5) %>%
  filter(collection == "Scaurinus")

```
All of those copper assignments have a scaled-likelihood of 1.

## Mixture assignment

Now try the mixture assignment:
```{r mixture}
# perform mixture-assignment on osu samples
mixture_assign <- infer_mixture(reference = revised_ref, mixture = sp_mix, gen_start_col = 5, method = "MCMC", reps = 2000, burn_in = 100)

# That was fast, let's take a look
head(mixture_assign)

# the individual data is in 
mixture_assign$indiv_posteriors %>%
  arrange(desc(log_likelihood))

# are there any rockfish that don't seem like the correct species is in the reference?
osu_assignments <- mixture_assign$indiv_posteriors %>%
  filter(PofZ == 1)

# get rid of the missing loci column because it messes up the .csv 
osu_assign2 <- osu_assignments[,-10]

# take a look at the z-scores for samples assigned to copper
osu_assign2 %>%
  filter(repunit == "Scaurinus") %>%
  filter(z_score > 2)
```
There are 23 (out of 111) copper samples with a z-score > 2, indicating that they are two standard deviations away from the mean for copper samples. However, none of them have a z-score > 3, so no obvious major species misassignments here.

It might be a bit more worrisome if the particular samples that Brittany is concerned about also have the highest z-scores.

```{r all-assignments}
# I there are individual assignments for each sample to each reference.
# I want to take only the top assignment for each sample.
keeper_assign <- mixture_assign$indiv_posteriors %>%
  group_by(indiv) %>%
  filter(PofZ > 0.5) %>%
  arrange(desc(PofZ))

keeper_assign
```

## Add some meta data 

Using a PofZ of 0.5, we keep everyone in the assignment data frame.

The `meta` file should contain all the samples for Brittany's project.

```{r add-meta-data}
brit_all_assign <- meta %>%
  left_join(., keeper_assign, by = c("NMFS_DNA_ID" = "indiv"))

brit_all_assign %>%
  select(1:5,7:9,17,25:32) %>%
  write_csv("csv_outputs/updated_osu_estuary_assignments_05pofz.csv")

```

Unassigned samples:
```{r}
# and a list of the samples that were not assigned (for one reason or another)
brit_all_assign %>%
  anti_join(., keeper_assign, by = c("NMFS_DNA_ID" = "indiv")) %>%
  #group_by(BOX_ID) %>%
  #tally() 
  select(1:32) %>%
  write_csv("csv_outputs/updated_osu_unassigned_samples_05pofz.csv")
  
```


One final thing - can I quickly look at the sample date of the copper rockfish?

```{r}
brit_all_assign %>%
  filter(repunit == "Scaurinus") %>%
  select(COLLECTION_DATE, LENGTH, z_score, PofZ)
  
```
Well, still a number of copper rockfish assignments in September, including the two tiny fish (25 and 26 mm, I'd assume).

The only other question would be if the meta data got mixed up. But generally, that would result in an off-set or issues for many samples rather than just two. 

