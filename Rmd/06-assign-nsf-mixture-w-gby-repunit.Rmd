---
title: "lumping gopher and black-and-yellow in the reference file"
output: html_notebook
---

Since we can't reliably tell the difference between them, we'll create one reporting group for gopher/black-and-yellow and then use high confidence assignments to that group.

To start off with, let's load data and libs:
```{r load-stuff}
library(tidyverse)
library(CKMRsim)
library(stringr)
library(readxl)
library(rubias)

meta <- readRDS("../../nsf-kelp-rockfish-ckmr/data/processed/meta-data-tibble.rds") %>%
  filter(REPORTED_LIFE_STAGE != "Extrusion Larvae") %>% # remove the extrustion larvae
  filter(REPORTED_LIFE_STAGE != "Adult") %>% # these are mothers for the larvae
  filter(REPORTED_LIFE_STAGE != "ADULT") %>% # just the juveniles for this analysis
  filter(SPECIES != "melanops") # no black rockfish for this.

genos <- readRDS("../nsf_data/processed/called_genos_na_explicit.rds") %>%
  filter(NMFS_DNA_ID != "Morin") # remove the data for Phil Morin
samples <- readRDS("../nsf_data/processed/sample-sheet-tibble.rds") %>%
  filter(NMFS_DNA_ID %in% meta$NMFS_DNA_ID)
```

## Some initial filters

### Take highest read-depth call for multiply-genotyped DNA_IDs

I'm not sure if there are any of these, but best to leave it in here...
if an individual is multiply-genotyped, take the
genotype with the highest total read depth.  
```{r take-just-one}
# slow-ish function to get the total read depth column
tdepth <- function(a, d) {
  if(any(is.na(a))) {
    return(NA)
  }
  if(a[1]==a[2]) {
    return(d[1])
  } else {
    return(d[1] + d[2])
  }
  
}
# this takes the highest read-depth instance of each duplicately-genotyped individual.
geno_one_each <- genos %>%
  group_by(NMFS_DNA_ID, locus, gtseq_run, id) %>%
  mutate(total_depth = tdepth(allele, depth)) %>%
  ungroup() %>%
  arrange(NMFS_DNA_ID, locus, total_depth, gtseq_run, id, depth) %>%
  group_by(NMFS_DNA_ID, locus) %>%
  mutate(rank = 1:n()) %>%
  ungroup() %>%
  filter(rank <= 2)
```

### Remove the 6 loci which Hayley has been removing

```{r remove-loci}
# read in a list of the 6 loci
to_remove <- read_csv("../data/loci_to_remove.csv")

# only keep the loci that are not those 6
keepers <- geno_one_each %>%
  anti_join(., to_remove, by = "locus")
```

```{r how-many-now}
unique_ids <- samples %>%
  select(NMFS_DNA_ID) %>%
  unique()

keepers <- keepers %>%
  inner_join(., unique_ids)

```


### Toss out indivs with data at fewer than 25 loci
Now, toss out any individual with fewer than 25 non-missing loci
```{r toss-missers}
no_hi_missers <- keepers %>% 
  group_by(NMFS_DNA_ID) %>%
  filter(sum(!is.na(allele)) >= (25*2))
```
So, we started with `r length(unique(geno_one_each$NMFS_DNA_ID))` 
and after filtering out indivs with fewer than 75 genotyped loci, we were left with 
`r length(unique(no_hi_missers$NMFS_DNA_ID))` individuals.  Those are the ones that
we will run through rubias to identify to species.


## Read in baseline genotypes and remove loci and individuals with too much missing data

```{r read-spp-genos}
# read in genotypes identified to species using rubias
spp <- read_csv("../data/reported_haplotype_SebSppID_11102017.csv")

select_spp <- spp %>%
  select(group, locus, indiv.ID, haplotype.1, haplotype.2)

spp.id <- select_spp %>%
  gather("gene_copy", "allele", 4:5) %>%
  mutate(gene_copy = ifelse(gene_copy == "haplotype.1", 1, 2))

# only keep the loci that are not the 6 removed from the previous dataset
spp.id_loc <- spp.id %>%
  anti_join(., to_remove, by = "locus")
# that should leave 90 loci 

# remove the hi-missers
spp.id_no_missers <- spp.id_loc %>% 
  group_by(indiv.ID) %>%
  filter(sum(!is.na(allele)) >= (25*2))

# how many were removed?
spp.id_no_missers %>%
  select(indiv.ID) %>%
  unique()
```
So we started with 1,535 samples in the baseline and after filtering for missing data, 1,515 remain.[we don't want samples with tons of missing data defining our baseline]

```{r how-many-per-spp-in-baseline}
spp.id_no_missers %>%
  select(indiv.ID, group) %>%
  unique() %>%
  ungroup() %>%
  group_by(group) %>%
  tally() %>%
  arrange(desc(n))

```


From the .csv output from microhaplot, we need to reformat the data for rubias.
Here's where I will also create a single reporting unit for gopher/black-and-yellow using `ifelse`.
```{r format-reference-for-rubias}
# add reference column to prepare data for rubias
spp.id_loc1 <- spp.id_no_missers %>%
  mutate(sample_type = "reference")

# add the repunit column that is identical to the group in this case, except create a joint group for GBY.
x <- spp.id_loc1  %>%
  mutate(repunit = ifelse(group == "Scarnatus", "Schrysomelas", group))

# reorder the columns and get the data frame in the right format
spp.id1 <- x[,c(6,7,1,3,2,4:5)]
spp.id2 <- spp.id1 %>%
  rename(collection = group) %>%
  rename(indiv = indiv.ID)
```

To ensure that haplotypes are coded identically across both the reference and mixture genotypes, we need to combine the two data sets, and then change haplotypes into numeric alleles.
```{r format-the-mixture}
# get the reference and mixture data frames into the same format
no_hi_missers2 <- no_hi_missers %>%
  dplyr::select(NMFS_DNA_ID, locus, gene_copy, allele) %>%
  rename(indiv = NMFS_DNA_ID) %>%
  mutate(sample_type = "mixture") %>%
  mutate(repunit = NA) %>%
  mutate(collection = "nsf_samples")

# reorder the columns for the mixture data frame
no_hi_missers3 <- no_hi_missers2[, c(5:7,1:4)]

# combine both data sets into a single df
alleles <- bind_rows(spp.id2, no_hi_missers3)

```


Here we turn alleles into integers, spread the data frame, and then get it into the right format to run rubias:
```{r spread-genos}
# first make integers of the alleles
alle_idxs <- alleles %>% 
  #select(NMFS_DNA_ID, locus, gene_copy, allele) %>%
  group_by(locus) %>%
  mutate(alleidx = as.integer(factor(allele, levels = unique(allele)))) %>%
  ungroup() %>%
  arrange(indiv, locus, alleidx) # rubias can handle NA's, so no need to change them to 0's
  
# select just the columns to retain and spread the alleles
alle_idx2 <- alle_idxs[,-7]
  
two_col <- alle_idx2 %>%
  unite(loc, locus, gene_copy, sep = ".") %>%
  spread(loc, alleidx)
```

We will use `infer_mixture` in rubias, which requires two separate data frames, one with the reference genotypes and the other with the mixture. 

I'll split the data frame that I created (but it needed to be bunged together for the conversion of alleles to integers).
```{r split-frames}
# split up the reference and mixture data frames
sp_mix <- two_col %>%
  filter(sample_type == "mixture")

sp_ref <- two_col %>%
  filter(sample_type == "reference")

# how many gopher v. black-and-yellow rockfishes are in the reference file?
# sp_ref %>%
#   filter(repunit %in% c("Scarnatus", "Schrysomelas")) %>% # 350 combined.
#   filter(repunit == "Schrysomelas") # 110 of them are black-and-yellow.
```

# I'm not equalizing gopher/black-and-yellow because I'm using them for assignment to a single repunit.
Experiment with equalizing the number of gopher/black-and-yellow rockfish in the reference file. Let's do 110 of each.

```{r equalize-ref-gby}
gopher_ref <- sp_ref %>%
  filter(collection == "Scarnatus") %>%
  sample_n(110, replace = FALSE)

# now create a reference that removes gopher from the reference and then put back just the 110 we want
spp_reference <- sp_ref %>%
  filter(collection != "Scarnatus") %>%
  bind_rows(., gopher_ref)
```

Now, with the two data frames separated, run the `infer mixture` analysis:
```{r run-mixture}
# perform mixture-assignment on baseline colony samples
mix_assign <- infer_mixture(reference = spp_reference, mixture = sp_mix, gen_start_col = 5, method = "MCMC", reps = 3000, burn_in = 200)
```

```{r look-at-assignments}
# That was fast, let's take a look
head(mix_assign)

# the individual data is in 
mix_assign$indiv_posteriors %>%
  arrange(desc(log_likelihood))

# look at the fish that were assigned with > 50% confidence
mix_assign$indiv_posteriors %>%
  group_by(indiv, repunit) %>%
  #summarise(PofZ = sum(PofZ)) %>%
  filter(PofZ > 0.5) %>%
  rename(NMFS_DNA_ID = indiv) %>%
  select(-missing_loci) %>%
  write_csv("csv_outputs/nsf-PofZ-50-rubias-all-samples.csv")


# What about at higher confidence?
# PofZ > 0.99
indiv_ass <- mix_assign$indiv_posteriors %>%
  group_by(indiv, repunit) %>%
  summarise(PofZ = sum(PofZ)) %>%
  filter(PofZ > 0.99) %>%
  rename(NMFS_DNA_ID = indiv) %>%
  write_csv("csv_outputs/nsf-PofZ-99-gby-single_repu-samples.csv")

# What about at higher confidence?
# PofZ > 0.99
mix_assign$indiv_posteriors %>%
  group_by(indiv, repunit) %>%
  summarise(PofZ = sum(PofZ)) %>%
  filter(PofZ > 0.99) %>%
  rename(NMFS_DNA_ID = indiv) %>%
  ungroup() %>%
  group_by(repunit) %>%
  tally() %>%
  arrange(desc(n)) %>%
  write_csv("csv_outputs/nsf-PofZ-99-gby-single_repu-summary.csv")

```
The posterior means of group membership in each collection is in the PofZ column.

And the number of gopher/black-and-yellow from that?
```{r}
indiv_ass %>%
  filter(repunit == "Scaurinus")
```


## Species assignments for the metadata

I chatted with Emily Saarman about the species identities of samples to help them understand the fate of each fish sampled.

Initially, let's see what we can do matching up samples with metadata:
```{r}
meta %>%
  left_join(indiv_ass, by = "NMFS_DNA_ID") %>%
  filter(is.na(repunit)) # I wonder if some of these were not genotyped because they weren't the target species?

```

Take a look at some of the collection year info
```{r}
indiv_ass %>%
  left_join(meta, by = "NMFS_DNA_ID") %>%
  select(NMFS_DNA_ID, repunit, COLLECTION_DATE, LENGTH) %>%
  tally() %>%
  arrange(desc(n))
```
How to make sure that these are consistent?
```{r}
indiv_ass %>%
  left_join(meta, by = "NMFS_DNA_ID") %>%
  select(NMFS_DNA_ID, repunit, COLLECTION_DATE, LENGTH) %>%
  filter(NMFS_DNA_ID == "R027572")
```
Yeah, just duplicates in the metadata. We can deal with that by just taking one of each duplicate.

```{r}
assign_w_meta <- indiv_ass %>%
  left_join(meta, by = "NMFS_DNA_ID") %>%
  select(NMFS_DNA_ID, repunit, COLLECTION_DATE, LENGTH, SPECIES) %>%
  unique()

assign_w_meta
```

Is there a good way to filter by collection date?

```{r}

```



## Everything above has been modified for the single-repunit for GBY.
# Below has not been modified.

```{r}
# What about at higher confidence?
# PofZ > 0.99
# single_repunit <- mix_assign$indiv_posteriors %>%
#   group_by(repunit) %>%
#   filter(PofZ > 0.99) %>%
#   filter(repunit == "Schrysomelas") %>%
#   rename(NMFS_DNA_ID = indiv) %>%
#   select(-missing_loci) %>%
#   write_csv("csv_outputs/gby_repunit_PofZ99.csv")
  
```


### Fish assigned at > 0.99 PofZ to gopher or black-and-yellow, or the single repunit

Here I have the results for all of these things.
```{r}
single_spp <- read_csv("csv_outputs/nsf-GBY-PofZ99.csv")

```

What is the intersection and the union of the single-species assignments and the single repunit assignments?

```{r}
single_spp %>%
  anti_join(single_repunit, by = "NMFS_DNA_ID")
```
There are 522 fish that are in the single species data that are not included in the single repunit data. 

Let's look at the union of the two data sets
```{r}
union(single_spp, single_repunit) %>%
  select(NMFS_DNA_ID, collection) %>%
  unique() %>% # only one entry per fish
  write_csv("csv_outputs/nsf-GBY-spp-and-repunit-PofZ99.csv")
```
That gets me to 4,361 fish. If there are 5,083 that were assigned to either black-and-yellow or gopher at a PofZ > 0.5, then I'm only losing 772 by taking this approach. That seems like the most defensible option.

## checking on removed samples
Some of my top sibs were removed. Let's figure out why.

```{r}
single_spp %>%
  filter(NMFS_DNA_ID == "R027243")
  
```

```{r}
mix_assign$indiv_posteriors %>%
  filter(indiv == "R027243") %>%
  arrange(desc(PofZ))
```
What about its partner?
```{r}
mix_assign$indiv_posteriors %>%
  filter(indiv == "R031406") %>%
  arrange(desc(PofZ))

```
There's something interesting going on here with partial ancestry. For example, what if the fish look alike because they are hybrid-esque, or they possess some of the same ambiguous alleles that make differentiating gopher and black-and-yellow difficult because they are actualy full-siblings.


So what happened in my earlier analysis is that even though this fish was assigned to the Schrysomelas repunit at nearly 100%, the collection business messed it up.

So I probably need to summarize the PofZ after condensing the Scarnatus and Schrysomelas collections because Schrysomelas has two entries - one for the original Schrysomelas and one for the Scarnatus-turned-Schrysomelas.

Try that.
```{r}
mix_assign$indiv_posteriors %>%
  select(indiv, repunit, PofZ) %>%
  group_by(indiv, repunit) %>%
  summarise(PofZ = sum(PofZ)) %>%
  filter(indiv == "R027243") %>%
  arrange(desc(PofZ))
```

Great. Now I can actually implement the single repunit filter!

```{r}
mix_assign$indiv_posteriors %>%
  select(indiv, repunit, PofZ) %>%
  group_by(indiv, repunit) %>%
  summarise(PofZ = sum(PofZ)) %>%
  filter(PofZ > 0.99) %>%
  filter(repunit == "Schrysomelas") %>%
  write_csv("csv_outputs/nsf-single-repunit.csv")
  
```
Awesome! When I actually implement the filter correctly, all GBY samples assign to the single repunit with a PofZ > 0.99.



